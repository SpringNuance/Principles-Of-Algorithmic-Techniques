\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{amsfonts}
\graphicspath{ {./img/} }
\geometry{a4paper}

\title{Graded Exercise 7}
\author{Duong Le}
\date{}

\begin{document}
\maketitle

\section*{Problem 1}
\subsection*{a.}
We have, the Primal problem can be represent in the matrix form as minimizing $w^{T}x$, subject to $Ax \geq b$. In the context of this problem:
\begin{itemize}
\item $x$ is the variable vectors: $x = \left( \begin{smallmatrix} x_1 \\ x_2 \\ ... \\ x_m \end{smallmatrix} \right)$
\item $w$ is the weight vector with dimension $m$: $w = \left( \begin{smallmatrix} w_1 \\ w_2 \\ ... \\ w_m \end{smallmatrix} \right)$ 
\item $A$ is a $n \times m$ matrix, where every entry $a_{ij}$ is 1 if the set $S_j$ contains the element $e_i$, and zero otherwise: $A = \left( \begin{smallmatrix} a_{11} & a_{12} & ... & a_{1m} \\ a_{21} & a_{22} & ... & a_{2m} \\ ... \\ a_{n1} & a_{n2} & ... & a_{nm} \end{smallmatrix} \right)$ 
\item $b$ is a $n \times 1$ vector, each entry of $b$ is 1: $b = \left( \begin{smallmatrix} 1 \\ 1 \\ ... \\ 1 \end{smallmatrix} \right)$
\end{itemize}
$\Rightarrow$ The primal problem in matrix form is:
\[
\begin{aligned}
&\min_x \quad \begin{pmatrix} w_1 \\ w_2 \\ ... \\ w_m \end{pmatrix}^{T} \begin{pmatrix} x_1 \\ x_2 \\ ... \\ x_m \end{pmatrix} \\\\
&\text{s.t} \quad \begin{pmatrix} a_{11} & a_{12} & ... & a_{1m} \\ a_{21} & a_{22} & ... & a_{2m} \\ ... \\ a_{n1} & a_{n2} & ... & a_{nm} \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \\ ... \\ x_m \end{pmatrix} \geq \begin{pmatrix} 1 \\ 1 \\ ... \\ 1 \end{pmatrix} \\\\
\end{aligned} 
\]
We can derive the dual: maxmizing $b^{T}y$, subject to $A^Ty \leq w$:
\[
\begin{aligned}
&\max_y \quad \begin{pmatrix} 1 \\ 1 \\ ... \\ 1 \end{pmatrix}^{T} \begin{pmatrix} y_1 \\ y_2 \\ ... \\ y_n \end{pmatrix} \\\\
&\text{s.t} \quad \begin{pmatrix} a_{11} & a_{21} & ... & a_{m1} \\ a_{12} & a_{22} & ... & a_{m2} \\ ... \\ a_{1n} & a_{2n} & ... & a_{mn} \end{pmatrix} \begin{pmatrix} y_1 \\ y_2 \\ ... \\ y_n \end{pmatrix} \leq \begin{pmatrix} w_1 \\ w_2 \\ ... \\ w_m \end{pmatrix}
\end{aligned} 
\]
We can express the matrix form to the sum form:
\[
\begin{aligned}
&\max_y \quad \sum_{i=1}^{n}y_i \\\\
&\text{s.t} \quad \sum_{i:e_{i} \in S_j} y_{i} \leq w_j, \quad j = 1, 2, ..., m \\\\
\end{aligned} 
\]
$\Rightarrow$ The derived dual matches the given dual.

\pagebreak
\subsection*{b.}
We have:
\[
c(I) = \sum_{j \in I}w_j
\]
From the algorithm, set $j$ is added if and only if $\sum_{i:e_i \in S_j} y_i = w_j$. Thus:
\[
\begin{aligned}
\sum_{j \in I}w_j &= \sum_{j \in I} \sum_{i:e_i \in S_j}y_i \\
                           &\leq \sum_{j=1}^{m}\sum_{i:e_i \in S_j}y_i
\end{aligned}
\]
Now, if we denote $f_i = |{j:e_i\in S_j}|$. By definition, $f = \max_{i}|f_i|$, we get that:
\[
\begin{aligned}
\sum_{j=1}^{m}\sum_{i:e_i \in S_j}y_i &= \sum_{i=1}^{n} f_{i} y_{i} \\
                                                             &\leq \sum_{i=1}^{n}fy_{i} = f \sum_{i=1}^{n}y_{i} \\\\
\end{aligned}
\]
$\Longrightarrow$ $c(I) \leq f \sum_{i=1}^{n}y_{i}$

\pagebreak
\subsection*{c.}
Consider for an abitrary $y_i$. The given algorithm only increases $y_i$ until the constraint is tight, and $y$ start with the value 0. Thus $y_i$ is always non negative. Also, for each $i$, $y_i$ is increased once when $e_i$ is checked, and stop immediately if the constraint is tight. So the dual constraint is preserved.  \\\\
$\Rightarrow$ $y_i$ is a feasible solution throughtout the algorithm, and we can apply the weak duality theorem. \\\\
Let $x^*$ be the optimal solution for the primal problem, and denote the optimal cost for the primal problem as $OPT_{LP}$. By the weak duality theorem, we have that:
\[
OPT_{LP} = \sum_{j=1}^{m}w_{j}x^{*}_{j} \geq \sum_{i=1}^{n}b_{i}y_{i} = \sum_{i=1}^{n}y_{i} \quad \text{(Since $b_{i}$ = 1)}
\]
From the previous part, we have shown that:
\[
\begin{aligned}
c(I) &\leq f \sum_{i=1}^{n}y_{i} \\
&\leq f\sum_{j=1}^{m}w_{j}x^{*}_{j} = f \cdot OPT_{LP} \\\\
\end{aligned}
\]
Furthermore, the optimum cost of the interger problem is as most as good as the optimum cost for the relaxed problem, i.e., $OPT_{LP} \leq OPT$ (as in the lecture note) \\\\
$\Longrightarrow$ $c(I) \leq f \cdot OPT_{LP} \leq f \cdot OPT$

\pagebreak
\section*{Problem 2}
\subsection*{a.}
Consider an abitrary element $e_{i} \in U$, and denote $f_i = |{j:e_i\in S_j}|$. Thus by definition, $f = |\max_{i} f_{i}|$. Since $x^*$ is the set of optimal solution for the primal problem, we have:
\[
\sum_{j:e_{i} \in S_{j}}x^{*}_{j} \geq 1
\]
In order for the above constraint to be valid, at least one of the $x^{*}_{j}$ must have value at least $\frac{1}{f_i}$. Denote that set as $x^{*}_{i}$, we get:
\[
x^{*}_{i} \geq \frac{1}{f_i} \geq \frac{1}{f} \quad\text{(since $f = |\max_{i} f_{i}|$)}
\]
$\Rightarrow$ For each element, there will be at least one set contains that element and have value at least $\frac{1}{f}$. And that set will be included into $I$. \\\\
$\Longrightarrow$ The algorithm returns a cover $I$.

\pagebreak
\subsection*{b.}
Consider an abitrary set $x^{*}_{j} \in x^*$ that has value $1 / f_j \geq 1 / f$. So $x^{*}_{j}$ will be rounded to 1 and add to $I$. This means that the value and thus the cost of adding $x^{*}_{j}$ increased by a factor of $f_{j} \leq f$.  \\\\
$\Rightarrow$ Each chosen set will be increased in cost by at most a factor of $f$. \\\\ 
Consider also: in the worst case, all sets from the fractional solution will be chosen and increased in the cost by $f$ times. Thus, c(I) will be at most $f \cdot OPT_{LP}$, with $OTP_{LP}$ denotes the optimal cost for the fractional problem. Also, $OPT_{LP} \leq OPT$ (As in the lecture note). \\\\
$\Rightarrow$ $c(I) \leq f \cdot OPT$  

\end{document}